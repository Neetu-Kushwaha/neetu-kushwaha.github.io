<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Neetu Kushwaha | publications</title>
  <meta name="description" content="This is the personal website of Neetu Kushwaha">

  <!-- Fonts and Icons -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons" />

  <!-- CSS Files -->
  <link rel="stylesheet" href="/assets/css/all.min.css">
  <link rel="stylesheet" href="/assets/css/academicons.min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
</head>
<body>
  <!-- Header -->
  <nav id="navbar" class="navbar fixed-top navbar-expand-md grey lighten-5 z-depth-1 navbar-light">
    <div class="container-fluid p-0">
      
        <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Neetu</span> Kushwaha</a>
      
      <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
            
          
            
              <li class="nav-item ">
                  <a class="nav-link" href="/cv/">
                    curriculum vitae
                    
                  </a>
              </li>
            
          
            
          
            
              <li class="nav-item ">
                  <a class="nav-link" href="/projects/">
                    projects
                    
                  </a>
              </li>
            
          
            
              <li class="nav-item navbar-active font-weight-bold">
                  <a class="nav-link" href="/publications/">
                    publications
                    
                      <span class="sr-only">(current)</span>
                    
                  </a>
              </li>
            
          
            
              <li class="nav-item ">
                  <a class="nav-link" href="/teaching/">
                    teaching
                    
                  </a>
              </li>
            
          
            
          
        </ul>
      </div>
    </div>
  </nav>

  <!-- Scrolling Progress Bar -->
  <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>

  <!-- Content -->
  <div class="content">
    
  <h1>publications</h1>
  <!-- <h6><nobr><em>*</em></nobr> denotes equal contribution and joint lead authorship.</h6> -->


<p><br /></p>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.12491" target="_blank">
          Journal
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="stretcu2021c2f" class="col p-0">
      <h5 class="title mb-0">Electromagnetic optimization‚Äêbased clustering algorithm.</h5>
      <div class="author">
        
          
            
              
                <nobr><em>Neetu Kushwaha</em>,</nobr>
              
            
          
        
          
            
              
                
                <nobr>Millie Pant,</nobr>
          
        
          
            
              and
              
                
                  <nobr>Sugam Sharma</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
          Expert Systems 39.7 (2022): e12491.
          
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a> -->
        
        
        
        
        
        
        
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="http://arxiv.org/abs/2106.04072" target="_blank">arXiv</a> -->
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="stretcu2021c2f-abstract" class="collapse">
          <!-- <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            When faced with learning challenging new tasks, humans often follow sequences of steps that allow them to incrementally build up the necessary skills for performing these new tasks. However, in machine learning, models are most often trained to solve the target tasks directly.Inspired by human learning, we propose a novel curriculum learning approach which decomposes challenging tasks into sequences of easier intermediate goals that are used to pre-train a model before tackling the target task. We focus on classification tasks, and design the intermediate tasks using an automatically constructed label hierarchy. We train the model at each level of the hierarchy, from coarse labels to fine labels, transferring acquired knowledge across these levels. For instance, the model will first learn to distinguish animals from objects, and then use this acquired knowledge when learning to classify among more fine-grained classes such as cat, dog, car, and truck. Most existing curriculum learning algorithms for supervised learning consist of scheduling the order in which the training examples are presented to the model. In contrast, our approach focuses on the output space of the model. We evaluate our method on several established datasets and show significant performance gains especially on classification problems with many labels. We also evaluate on a new synthetic dataset which allows us to study multiple aspects of our method.
          </div> -->
        </div>
      </div>
      
    </div>
  </div>
</div>
</li></ol>
    </div>
  </div>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2021</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography">
        <li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://www.tandfonline.com/doi/abs/10.1080/0952813X.2019.1647557" target="_blank">
          Journal
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="braintasks2020" class="col p-0">
      <h5 class="title mb-0">Fuzzy electromagnetic optimisation clustering algorithm for collaborative filtering.</h5>
      <div class="author">
        
        <nobr><em>Neetu Kushwaha</em>,</nobr>
            
              
                
                  <!-- <nobr><a href="http://www.cs.cmu.edu/~mktoneva/" target="_blank">Neetu Kushwaha<nobr><em></em></nobr></a>,</nobr> -->
                
              
            
          
        
          
            
          
                
              
            
          
        
          
            
              and
              
              <nobr>Millie Pant</nobr>
                  <!-- <nobr><a href="http://www.cs.cmu.edu/~tom/" target="_blank">Millie Pant</a>.</nobr> -->
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
          Journal of Experimental & Theoretical Artificial Intelligence 33.4 (2021): 601-616.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#braintasks2020-abstract" role="button" aria-expanded="false" aria-controls="braintasks2020-abstract">Abstract</a> -->
        
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/brain-tasks-neurips/arxiv.pdf" target="_blank">PDF</a> -->
        
        
        
        
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/otiliastr/brain_task_effect" target="_blank">Code</a> -->
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="http://arxiv.org/abs/2009.08424" target="_blank">arXiv</a> -->
        
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://youtu.be/-SXlEhSTSi8" target="_blank">Video</a> -->
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="braintasks2020-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <!-- How meaning is represented in the brain is still one of the big open questions in neuroscience. Does a word (e.g., bird) always have the same representation, or does the task under which the word is processed alter its representation (answering "can you eat it?" versus "can it fly?")? The brain activity of subjects who read the same word while performing different semantic tasks has been shown to differ across tasks. However, it is still not understood how the task itself contributes to this difference. In the current work, we study Magnetoencephalography (MEG) brain recordings of participants tasked with answering questions about concrete nouns. We investigate the effect of the task (i.e. the question being asked) on the processing of the concrete noun by predicting the millisecond-resolution MEG recordings as a function of both the semantics of the noun and the task. Using this approach, we test several hypotheses about the task-stimulus interactions by comparing the zero-shot predictions made by these hypotheses for novel tasks and nouns not seen during training. We find that incorporating the task semantics significantly improves the prediction of MEG recordings, across participants. The improvement occurs 475-550ms after the participants first see the word, which corresponds to what is considered to be the ending time of semantic processing for a word. These results suggest that only the end of semantic processing of a word is task-dependent, and pose a challenge for future research to formulate new hypotheses for earlier task effects as a function of the task and stimuli. -->
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>


</ol>
    </div>
  </div>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2020</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://link.springer.com/article/10.1007/s11042-018-6900-x" target="_blank">
          Journal
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="stretcu2019graph" class="col p-0">
      <h5 class="title mb-0">	Textual data dimensionality reduction-a deep learning approach.</h5>
      <div class="author">
        
          
            
              
                <nobr><em>Neetu Kushwaha</em>,</nobr>
              
            
          
        
          
            
              
            
          
        
          
            
              and
              <nobr>Millie Pant</nobr>
                
                  <!-- <nobr><a href="http://www.sravi.org/" target="_blank">Millie Pant</a>.</nobr> -->
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
          Multimedia Tools and Applications 79 (2020): 11039-11050.
          
        </p>
      </div>
    
      <div class="col p-0">
<!--         
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2019graph-abstract" role="button" aria-expanded="false" aria-controls="stretcu2019graph-abstract">Abstract</a>
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/gam/9076-graph-agreement-models-for-semi-supervised-learning.pdf" target="_blank">PDF</a>
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/gam/appendix.pdf" target="_blank">Supplementary</a>
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/gam/gam-poster.pdf" target="_blank">Poster</a>
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/tensorflow/neural-structured-learning/tree/master/research/gam" target="_blank">Code</a> -->
        
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="stretcu2019graph-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <!-- Graph-based algorithms are among the most successful paradigms for solving semi-supervised learning tasks. Recent work on graph convolutional networks and neural graph learning methods has successfully combined the expressiveness of neural networks with graph structures. We propose a technique that, when applied to these methods, achieves state-of-the-art results on semi-supervised learning datasets. Traditional graph-based algorithms, such as label propagation, were designed with the underlying assumption that the label of a node can be imputed from that of the neighboring nodes. However, real-world graphs are either noisy or have edges that do not correspond to label agreement. To address this, we propose Graph Agreement Models (GAM), which introduces an auxiliary model that predicts the probability of two nodes sharing the same label as a learned function of their features. The agreement model is used when training a node classification model by encouraging agreement only for the pairs of nodes it deems likely to have the same label, thus guiding its parameters to better local optima. The classification and agreement models are trained jointly in a co-training fashion. Moreover, GAM can also be applied to any semi-supervised classification problem, by inducing a graph whenever one is not provided. We demonstrate that our method achieves a relative improvement of up to 72% for various node classification models, and obtains state-of-the-art results on multiple established datasets. -->
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>


<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://link.springer.com/chapter/10.1007/978-981-15-0751-9_82" target="_blank">
          Conference
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="platanios2019curriculummt" class="col p-0">
      <h5 class="title mb-0">Fuzzy particle swarm page rank clustering algorithm.</h5>
      <div class="author">
        
          
            
        <nobr><em>Neetu Kushwaha</em>,</nobr>
        <!-- <nobr><em></em>Neetu Kushwaha</em>,</nobr> -->
                  <!-- <nobr><em></em> Neetu Kushwaha</em>,</nobr> -->
                
              
            
          
          
        
          
            
              and
              
              <nobr>Millie Pant</nobr>
                  <!-- <nobr><a href="http://www.cs.cmu.edu/~tom/" target="_blank">Millie Pant</a>.</nobr> -->
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
          Soft Computing: Theories and Applications: Proceedings of SoCTA 2018. Springer Singapore, 2020.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#platanios2019curriculummt-abstract" role="button" aria-expanded="false" aria-controls="platanios2019curriculummt-abstract">Abstract</a> -->
        
        
        
        
        
        
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/eaplatanios/curriculum" target="_blank">Code</a> -->
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="http://arxiv.org/abs/1903.09848" target="_blank">arXiv</a> -->
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="platanios2019curriculummt-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            <!-- Current state-of-the-art NMT systems use large neural networks that are not only slow to train, but also often require many heuristics and optimization tricks, such as specialized learning rate schedules and large batch sizes. This is undesirable as it requires extensive hyperparameter tuning. In this paper, we propose a curriculum learning framework for NMT that reduces training time, reduces the need for specialized heuristics or large batch sizes, and results in overall better performance. Our framework consists of a principled way of deciding which training samples are shown to the model at different times during training, based on the estimated difficulty of a sample and the current competence of the model. Filtering training samples in this manner prevents the model from getting stuck in bad local optima, making it converge faster and reach a better solution than the common approach of uniformly sampling training examples. Furthermore, the proposed method can be easily applied to existing NMT models by simply modifying their input data pipelines. We show that our framework can help improve the training time and the performance of both recurrent neural network models and Transformers, achieving up to a 70% decrease in training time, while at the same time obtaining accuracy improvements of up to 2.2 BLEU. -->
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>

</ol>
    </div>
  </div>

  
<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2019</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://link.springer.com/article/10.1007/s11042-018-6324-7" target="_blank">
          Journal
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="fu2017brainzoom" class="col p-0">
      <h5 class="title mb-0">Modified particle swarm optimization for multimodal functions and its application.</h5>
      <div class="author">
        
          
            
              
                
                  
            
          
        <nobr><em>Neetu Kushwaha</em>,</nobr>
              
            
          
          
            
        and
        
        <nobr>Millie Pant</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
          Multimedia Tools and Applications 78 (2019): 23917-23947.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#fu2017brainzoom-abstract" role="button" aria-expanded="false" aria-controls="fu2017brainzoom-abstract">Abstract</a> -->
        
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/brainzoom/siam_paper.pdf" target="_blank">PDF</a> -->
        
        
        
        
        
        
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="fu2017brainzoom-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
             <!-- How close can we zoom in to observe brain activity? Our understanding is limited by the resolution of imaging modalities that exhibit good spatial but poor temporal resolution, or vice-versa. In this paper, we propose BRAINZOOM, an efficient imaging algorithm that cross-leverages multi-modal brain signals. BRAINZOOM (a) constructs high resolution brain images from multi-modal signals, (b) is scalable, and (c) is flexible in that it can easily incorporate various priors on the brain activities, such as sparsity, low rank, or smoothness. We carefully formulate the problem to tackle nonlinearity in the measurements (via variable splitting) and auto-scale between different modal signals, and judiciously design an inexact alternating optimization-based algorithmic framework to handle the problem with provable convergence guarantees. Our experiments using a popular realistic brain signal simulator to generate fMRI and MEG demonstrate that high spatio-temporal resolution brain imaging is possible from these two modalities. The experiments also suggest that smoothness seems to be the best prior, among several we tried.  -->
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://link.springer.com/chapter/10.1007/978-981-13-0923-6_19" target="_blank">
          Conference
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="zhao2017efficient" class="col p-0">
      <h5 class="title mb-0">A teaching‚Äìlearning-based particle swarm optimization for data clustering.</h5>
      <div class="author">
        
          
            
        <nobr><em>Neetu Kushwaha</em>,</nobr>
              
            
          
          
            
        and
        
        <nobr>Millie Pant</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
          Machine intelligence and signal analysis. Springer Singapore, 2019.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#zhao2017efficient-abstract" role="button" aria-expanded="false" aria-controls="zhao2017efficient-abstract">Abstract</a>
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/fetr/LLD_2017_paper_15.pdf" target="_blank">PDF</a>
        
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/fetr/poster_fetr_lld.pdf" target="_blank">Poster</a>
        
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="http://arxiv.org/abs/1702.04423" target="_blank">arXiv</a> -->
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="zhao2017efficient-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
             <!-- We propose a multi-convex framework for multitask learning that improves pre- dictions by learning relationships both between tasks and between features. Our framework is a generalization of related methods, that either learn task relationships, or feature relationships, but not both. We start with a hierarchical Bayesian model, and use the empirical Bayes method to transform the underlying inference problem into a multi-convex problem. To tackle the multi-convex optimization problem, we propose a block coordinate-wise minimization algorithm that has a closed form solution for each block subproblem. Naively these solutions would be expensive to compute, but by using the theory of doubly stochastic matrices, we are able to reduce the covariance learning subproblem to a minimum-weight perfect matching problem on a complete bipartite graph, and solve it analytically and efficiently. To solve the weight learning subproblem, we propose three different strategies that can be used no matter whether the instances are shared by multiple tasks or not. We demonstrate the efficiency of our method on both synthetic datasets and real-world datasets. Experiments show that the proposed optimization method is orders of magnitude faster than the previous projected gradient method, and our model is able to exploit the correlation structures among multiple tasks and features.  -->
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>

</ol>
    </div>
  </div>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2018</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://www.sciencedirect.com/science/article/abs/pii/S0167865517303999" target="_blank">
          Journal
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="stretcu2015multiple" class="col p-0">
      <h5 class="title mb-0">Magnetic optimization algorithm for data clustering.</h5>
      <div class="author">
        
          
            
              
                   
        <nobr><em>Neetu Kushwaha</em>,</nobr>
              
        <nobr>Millie Pant,</nobr>
        <nobr>Surya Kant,</nobr>
          
  
            
        and
        <nobr>Vinay Kumar Jain</nobr>
 
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          Pattern Recognition Letters 115 (2018): 59-65.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2015multiple-abstract" role="button" aria-expanded="false" aria-controls="stretcu2015multiple-abstract">Abstract</a> -->
        
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/videoPCA/bmvc_videopca.pdf" target="_blank">PDF</a> -->
        
        
        
        
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://drive.google.com/drive/folders/0B7CshFGxfi_5aW13T2h5RDZ3djQ" target="_blank">Code</a> -->
        
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="https://sites.google.com/site/multipleframesmatching/" target="_blank">Website</a> -->
        <!--  -->
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="stretcu2015multiple-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
             <!-- Automatic discovery of foreground objects in video sequences is an important prob- lem in computer vision with applications to object tracking, video segmentation and clas- sification. We propose an efficient method for the discovery of object bounding boxes and the corresponding soft-segmentation masks across multiple video frames. We offer a graph matching formulation for bounding box selection and refinement using second and higher order terms. Our objective function takes into consideration local, frame-based information, as well as spatiotemporal and appearance consistency over multiple frames. First, we find an initial pool of candidate boxes using a novel and fast foreground esti- mation method in video, based on Principal Component Analysis. Then, we match the boxes across multiple frames using pairwise geometric and appearance terms. Finally, we refine their location and soft-segmentation using higher order potentials that estab- lish appearance regularity over multiple frames. We test our method on the large scale YouTube-Objects dataset and obtain state-of-the-art results on several object classes.  -->
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://www.sciencedirect.com/science/article/abs/pii/S0167739X17321854" target="_blank">
          Journal
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="emim" class="col p-0">
      <h5 class="title mb-0">Link based BPSO for feature selection in big data text clustering.</h5>
      <div class="author">
        
          
            
        <nobr><em>Neetu Kushwaha</em>,</nobr>
              
     
          
        
          
            
              and
              
              <nobr>Millie Pant</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
          Future generation computer systems 82 (2018): 190-199.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#emim-abstract" role="button" aria-expanded="false" aria-controls="emim-abstract">Abstract</a> -->
        
        
        
        
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/emim/emim_poster.pdf" target="_blank">Poster</a> -->
        
        
        
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="emim-abstract" class="collapse">
          <!-- <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            In the past decade, we have witnessed significant advancements in image analysis methods.
        However, the analysis of molecular images such as fluorescent in situ hybridization (FISH) still
        relies heavily on manual evaluation by experts. For automated image analysis to be adopted by
        clinicians there is a need for more reliable tools that can extract rich information from molecular
        images. The first step in developing such tools is to evaluate the performance of state-of-the-art
        image analysis methods. This assessment could be further used to develop of a multi-method
        approach that would integrate partial information extracted by each constituent method, to build an
        augmented microscopic reality.
        We investigate a set of techniques which have shown promising results in the analysis of images
        that share many similarities with molecular images. Namely, wavelets, that have successfully been
        used to describe structural patterns in astronomical images [1], and Markov Random Fields. We
        apply them to a benchmark of molecular FISH images and evaluate their performance with respect
        to two key tasks: (1) denoising and thresholding; (2) segmentation and detection of various
        structures(e.g. interphase nuclei, metaphase chromosomes, multi-colored probes). We further test
        whether data from high-throughput Chromosome Conformation Capture (Hi-C) could enrich the
        information obtained.
        We show the results of our analysis and identify which techniques are best for describing certain
        properties of images (e.g. intensity, edges). We further discuss methodologies of integrating
        complementary methods and data to improve the overall performance.
        The integration of multiple methods can result in overall improvement with respected to key tasks
        in the analysis of molecular images. Coupling a multi-method approach with Chromosome
        Conformation Capture data can help to extract additional information from images.
        <br /><br />
        [1] Mertens, F., and Lobanov A. (2014) Wavelet-based decomposition and analysis of structural
        patterns in astronomical images. arXiv preprintarXiv:1410.3732
          </div> -->
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>

<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://link.springer.com/article/10.1007/s12652-018-0941-x" target="_blank">
          Journal
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="emim" class="col p-0">
      <h5 class="title mb-0">Fuzzy magnetic optimization clustering algorithm with its application to health care.</h5>
      <div class="author">
        
          
            
        <nobr><em>Neetu Kushwaha</em>,</nobr>
              
     
          
        
          
            
              and
              
                
              <nobr>Millie Pant</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
          Journal of Ambient Intelligence and Humanized Computing (2018): 1-10.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#emim-abstract" role="button" aria-expanded="false" aria-controls="emim-abstract">Abstract</a> -->
        
        
        
        
        
        
          <!-- <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/emim/emim_poster.pdf" target="_blank">Poster</a> -->
        
        
        
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="emim-abstract" class="collapse">
          <!-- <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            In the past decade, we have witnessed significant advancements in image analysis methods.
        However, the analysis of molecular images such as fluorescent in situ hybridization (FISH) still
        relies heavily on manual evaluation by experts. For automated image analysis to be adopted by
        clinicians there is a need for more reliable tools that can extract rich information from molecular
        images. The first step in developing such tools is to evaluate the performance of state-of-the-art
        image analysis methods. This assessment could be further used to develop of a multi-method
        approach that would integrate partial information extracted by each constituent method, to build an
        augmented microscopic reality.
        We investigate a set of techniques which have shown promising results in the analysis of images
        that share many similarities with molecular images. Namely, wavelets, that have successfully been
        used to describe structural patterns in astronomical images [1], and Markov Random Fields. We
        apply them to a benchmark of molecular FISH images and evaluate their performance with respect
        to two key tasks: (1) denoising and thresholding; (2) segmentation and detection of various
        structures(e.g. interphase nuclei, metaphase chromosomes, multi-colored probes). We further test
        whether data from high-throughput Chromosome Conformation Capture (Hi-C) could enrich the
        information obtained.
        We show the results of our analysis and identify which techniques are best for describing certain
        properties of images (e.g. intensity, edges). We further discuss methodologies of integrating
        complementary methods and data to improve the overall performance.
        The integration of multiple methods can result in overall improvement with respected to key tasks
        in the analysis of molecular images. Coupling a multi-method approach with Chromosome
        Conformation Capture data can help to extract additional information from images.
        <br /><br />
        [1] Mertens, F., and Lobanov A. (2014) Wavelet-based decomposition and analysis of structural
        patterns in astronomical images. arXiv preprintarXiv:1410.3732
          </div> -->
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
</ol>
    </div>
  </div>



  </div>

  <!-- Footer -->
  <footer>
    &copy; Copyright 2021 Neetu Kushwaha.
    
    
  </footer>

  <!-- Core JavaScript Files -->
  <script src="/assets/js/jquery.min.js" type="text/javascript"></script>
  <script src="/assets/js/popper.min.js" type="text/javascript"></script>
  <script src="/assets/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="/assets/js/mdb.min.js" type="text/javascript"></script>
  <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous"></script>
  <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
  <script src="/assets/js/common.js"></script>

  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    $(document).ready(function() {
      var navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      var progressBar = $('#progress');
      progressBar.css({ 'top': navbarHeight });
      var getMax = function() { return $(document).height() - $(window).height(); }
      var getValue = function() { return $(window).scrollTop(); }   
      // Check if the browser supports the progress element.
      if ('max' in document.createElement('progress')) {
        // Set the 'max' attribute for the first time.
        progressBar.attr({ max: getMax() });
        progressBar.attr({ value: getValue() });
    
        $(document).on('scroll', function() {
          // On scroll only the 'value' attribute needs to be calculated.
          progressBar.attr({ value: getValue() });
        });

        $(window).resize(function() {
          var navbarHeight = $('#navbar').outerHeight(true);
          $('body').css({ 'padding-top': navbarHeight });
          $('progress-container').css({ 'padding-top': navbarHeight });
          progressBar.css({ 'top': navbarHeight });
          // On resize, both the 'max' and 'value' attributes need to be calculated.
          progressBar.attr({ max: getMax(), value: getValue() });
        });
      } else {
        var max = getMax(), value, width;
        var getWidth = function() {
          // Calculate the window width as a percentage.
          value = getValue();
          width = (value/max) * 100;
          width = width + '%';
          return width;
        }
        var setWidth = function() { progressBar.css({ width: getWidth() }); };
        setWidth();
        $(document).on('scroll', setWidth);
        $(window).on('resize', function() {
          // Need to reset the 'max' attribute.
          max = getMax();
          setWidth();
        });
      }
    });
  </script>

  <!-- Code Syntax Highlighting -->
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
  <script src="/assets/js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- Script Used for Randomizing the Projects Order -->
  <!-- <script type="text/javascript">
    $.fn.shuffleChildren = function() {
      $.each(this.get(), function(index, el) {
        var $el = $(el);
        var $find = $el.children();

        $find.sort(function() {
          return 0.5 - Math.random();
        });

        $el.empty();
        $find.appendTo($el);
      });
    };
    $("#projects").shuffleChildren();
  </script> -->

  <!-- Project Cards Layout -->
  <script type="text/javascript">
    var $grid = $('#projects');

    // $grid.masonry({ percentPosition: true });
    // $grid.masonry('layout');

    // Trigger after images load.
    $grid.imagesLoaded().progress(function() {
      $grid.masonry({ percentPosition: true });
      $grid.masonry('layout');
    });
  </script>

  <!-- Enable Tooltips -->
  <script type="text/javascript">
    $(function () {
      $('[data-toggle="tooltip"]').tooltip()
    })
  </script>

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', '', 'auto');
    ga('send', 'pageview');
  </script>
</body>
</html>
